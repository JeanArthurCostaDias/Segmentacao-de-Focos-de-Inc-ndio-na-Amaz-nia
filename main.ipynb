{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "from osgeo import gdal, osr\n",
    "from pyproj import Transformer\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./dataset\"\n",
    "data_dir = pathlib.Path(dataset)\n",
    "imgs = sorted(list(data_dir.glob(\"imgs/*/*.tif\")))\n",
    "masks = sorted(list(data_dir.glob(\"msks/*/*.tif\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "\n",
    "# Lista para armazenar as porcentagens\n",
    "percent_ones = []\n",
    "\n",
    "# Primeiro loop para calcular a porcentagem de pixels 1\n",
    "for i in range(len(imgs)):\n",
    "    mask = gdal.Open(str(masks[i])).ReadAsArray()\n",
    "    percent = np.sum(mask == 1) / mask.size  # Percentual de pixels 1\n",
    "    percent_ones.append((percent, i))  # Guardar junto com o índice da imagem\n",
    "\n",
    "# Ordenar do maior para o menor\n",
    "top_5 = sorted(percent_ones, reverse=True, key=lambda x: x[0])[:10]\n",
    "\n",
    "# Segundo loop para exibir as 5 melhores imagens\n",
    "for rank, (_, i) in enumerate(top_5):\n",
    "    mask = gdal.Open(str(masks[i])).ReadAsArray()\n",
    "    img = gdal.Open(str(imgs[i]))\n",
    "    img_array = img.ReadAsArray()\n",
    "\n",
    "    # Selecionar bandas RGB (B7 = SWIR2, B6 = SWIR1, B2 = Azul)\n",
    "    rgb = np.stack([img_array[6], img_array[5], img_array[2]], axis=-1)\n",
    "\n",
    "    # Normalizar para 0-1\n",
    "    rgb = rgb.astype(np.float32)\n",
    "    min_val = np.percentile(rgb, 2)\n",
    "    max_val = np.percentile(rgb, 98)\n",
    "    rgb = np.clip((rgb - min_val) / (max_val - min_val), 0, 1)\n",
    "    #rgb = np.power(rgb, 0.8)  # Reduz brilho excessivo\n",
    "\n",
    "\n",
    "    # Exibir a imagem\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.suptitle(f\"Imagem {i} - {percent_ones[i][0]*100:.2f}% de pixels 1\")\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(rgb)\n",
    "    plt.imshow(mask, cmap=\"Reds\", alpha=0.5)  # Sobrepor máscara\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = []\n",
    "lon = []\n",
    "\n",
    "for i in masks:\n",
    "    # Abrir a imagem\n",
    "    msk = gdal.Open(str(i))\n",
    "\n",
    "    # Obter transformação geoespacial\n",
    "    gt = msk.GetGeoTransform()\n",
    "\n",
    "    # Obter tamanho da imagem\n",
    "    cols = msk.RasterXSize\n",
    "    rows = msk.RasterYSize\n",
    "\n",
    "    # Pixel central\n",
    "    x_center = cols // 2\n",
    "    y_center = rows // 2\n",
    "\n",
    "    # Calcular coordenadas UTM (ou outra projeção da imagem)\n",
    "    x_geo = gt[0] + x_center * gt[1] + y_center * gt[2]\n",
    "    y_geo = gt[3] + x_center * gt[4] + y_center * gt[5]\n",
    "\n",
    "    # Obter sistema de referência espacial (SRS)\n",
    "    proj = osr.SpatialReference(wkt=msk.GetProjection())\n",
    "\n",
    "    # Pegar EPSG do raster\n",
    "    epsg_code = proj.GetAuthorityCode(None)\n",
    "\n",
    "    if epsg_code is not None:\n",
    "        epsg_code = int(epsg_code)  # Converter para inteiro\n",
    "\n",
    "        # Criar um transformador dinâmico do EPSG da imagem para WGS84\n",
    "        transformer = Transformer.from_crs(f\"EPSG:{epsg_code}\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "        # Converter coordenadas\n",
    "        lon_wgs84, lat_wgs84 = transformer.transform(x_geo, y_geo)\n",
    "\n",
    "        # Salvar coordenadas convertidas\n",
    "        lat.append(lat_wgs84)\n",
    "        lon.append(lon_wgs84)\n",
    "\n",
    "        #print(f\"Imagem: {i}, EPSG: {epsg_code}, Lat: {lat_wgs84}, Lon: {lon_wgs84}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"EPSG não encontrado para {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar figura\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Adicionar feições básicas (costas, rios, estados, países)\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=1)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.LAND, color='lightgray')\n",
    "ax.add_feature(cfeature.OCEAN, color='lightblue')\n",
    "\n",
    "# Definir limites do mapa (América do Sul)\n",
    "ax.set_extent([-85, -30, -55, 15], crs=ccrs.PlateCarree())  # (lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "# Adicionar os pontos das imagens\n",
    "ax.scatter(lon, lat, color='red', marker='o', s=10, transform=ccrs.PlateCarree(), label=\"Pontos\")\n",
    "\n",
    "# Legenda e título\n",
    "ax.legend()\n",
    "plt.title(\"Localização das Imagens do Landsat 8 na Amazônia\")\n",
    "plt.savefig(\"mapa.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão em Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do caminho para os arquivos\n",
    "dataset = \"./dataset\"\n",
    "data_dir = pathlib.Path(dataset)\n",
    "imgs = sorted(list(data_dir.glob(\"imgs/*/*.tif\")))\n",
    "masks = sorted(list(data_dir.glob(\"msks/*/*.tif\")))\n",
    "\n",
    "# Função para calcular a fração de pixels 1 (fogo) na máscara\n",
    "def calc_pos_ratio(mask_path):\n",
    "    mask = gdal.Open(str(mask_path)).ReadAsArray()  # Carregar máscara como array\n",
    "    return np.sum(mask == 1) / mask.size  # Razão de pixels fogo (1) sobre total\n",
    "\n",
    "# Calcular a fração de fogo em cada máscara\n",
    "ratios = np.array([calc_pos_ratio(mask) for mask in masks])\n",
    "\n",
    "# Criar categorias (bins) para os valores contínuos de ratios\n",
    "num_bins = min(10, len(ratios) // 2)  # Número adequado de bins (mínimo 2)\n",
    "binned_ratios = pd.qcut(ratios, q=num_bins, labels=False, duplicates=\"drop\")  # Estratificação mais equilibrada\n",
    "\n",
    "# Divisão estratificada usando os bins\n",
    "X_train, X_temp, y_train, y_temp, bins_train, bins_temp = train_test_split(\n",
    "    imgs, masks, binned_ratios, test_size=0.3, stratify=binned_ratios, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=bins_temp, random_state=42\n",
    ")\n",
    "\n",
    "# Verificação dos tamanhos das divisões\n",
    "print(f\"Tamanho do Treino: {len(X_train)}, Validação: {len(X_val)}, Teste: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as frações de fogo (1) e sem fogo (0)\n",
    "fire_fraction = (ratios.sum() / len(ratios)) * 100\n",
    "no_fire_fraction = 100 - fire_fraction\n",
    "\n",
    "# Dados para o gráfico\n",
    "fractions = [fire_fraction, no_fire_fraction]\n",
    "labels = [\"Fogo\", \"Sem Fogo\"]\n",
    "\n",
    "# Ajuste para aproximar as barras\n",
    "x_pos = [0, 1]  # Posições para as barras\n",
    "bar_width = 0.5  # Ajuste da largura das barras\n",
    "\n",
    "# Criar o gráfico de barras\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(x_pos, fractions, color=[\"red\", \"green\"], edgecolor=\"black\", alpha=0.7, width=bar_width)\n",
    "\n",
    "# Adicionar rótulos e título\n",
    "plt.ylabel(\"Porcentagem (%)\")\n",
    "plt.title(\"Distribuição de Fogo e Sem Fogo no Dataset\")\n",
    "\n",
    "# Adicionar as labels\n",
    "plt.xticks(x_pos, labels)\n",
    "\n",
    "# Exibir os valores no topo das barras\n",
    "for i in range(len(fractions)):\n",
    "    plt.text(x_pos[i], fractions[i] + 1, f\"{fractions[i]:.2f}%\", ha=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Para Segmentação de Focos de Incêndio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireModel(pl.LightningModule):\n",
    "    def __init__(self, arch, encoder_name, in_channels, out_classes, lr=1e-4, **kwargs):\n",
    "        super(FireModel, self).__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch,\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=in_channels,\n",
    "            classes=out_classes,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.arch = arch.lower()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # for image segmentation dice loss could be the best first choice\n",
    "        self.criterion = smp.losses.FocalLoss(smp.losses.BINARY_MODE, normalized=True)\n",
    "\n",
    "        # initialize step metics\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    # ===================== TREINAMENTO =======================\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\" Passo de treinamento \"\"\"\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.criterion(y_hat, y.float())\n",
    "\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    # ===================== OTIMIZADOR =======================\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_average = torch.mean(torch.tensor(self.training_step_outputs))\n",
    "\n",
    "        # Log da média de perda de treinamento no final da época\n",
    "        self.log(\"training_epoch_average\", epoch_average)\n",
    "\n",
    "        self.training_step_outputs.clear()  # Free memory\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.criterion(y_hat, y.float()).detach()\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_average = torch.mean(torch.tensor(self.validation_step_outputs))\n",
    "        self.log(\"validation_epoch_average\", epoch_average)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.criterion(y_hat, y.float())\n",
    "        self.test_step_outputs.append(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        epoch_average = torch.mean(torch.tensor(self.test_step_outputs))\n",
    "        self.log(\"test_epoch_average\", epoch_average)\n",
    "        self.test_step_outputs.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do Dataset personalizado\n",
    "class FireSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_paths, mask_paths, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_ds = gdal.Open(str(self.img_paths[idx]))\n",
    "        nir = img_ds.ReadAsArray(5).astype(np.float32)\n",
    "        swir = img_ds.ReadAsArray(7).astype(np.float32)\n",
    "        tir = img_ds.ReadAsArray(10).astype(np.float32)\n",
    "        img = np.stack([nir, swir, tir], axis=0)\n",
    "        \n",
    "        min_val = np.percentile(img, 2)\n",
    "        max_val = np.percentile(img, 98)\n",
    "        img = np.clip(img/img.max(), 0, 1)\n",
    "\n",
    "        mask_ds = gdal.Open(str(self.mask_paths[idx]))\n",
    "        mask = mask_ds.ReadAsArray().astype(np.uint8)\n",
    "\n",
    "        img = torch.tensor(img).float()\n",
    "        mask = torch.tensor(mask).long()\n",
    "\n",
    "        if len(mask.shape) == 2:\n",
    "            mask = mask.unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "# Definição das transformações (ex: augmentação)\n",
    "transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Combina treino e validação para cross-validação\n",
    "all_img_paths = X_train + X_val\n",
    "all_mask_paths = y_train + y_val\n",
    "\n",
    "num_folds = 3 \n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "architectures =  [\"unet\", \"deeplabv3plus\", \"segformer\"]\n",
    "\n",
    "for arch in architectures:\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(all_img_paths)):\n",
    "        model = FireModel(arch, \"resnet34\", 10, 1) #resnet34\n",
    "        print(f\"\\nFold {fold + 1}/{num_folds}\")\n",
    "        \n",
    "        # Cria subsets para o fold atual\n",
    "        train_img = [all_img_paths[i] for i in train_idx]\n",
    "        train_mask = [all_mask_paths[i] for i in train_idx]\n",
    "        val_img = [all_img_paths[i] for i in val_idx]\n",
    "        val_mask = [all_mask_paths[i] for i in val_idx]\n",
    "\n",
    "        # Cria datasets e dataloaders\n",
    "        train_dataset = FireSegmentationDataset(train_img, train_mask, transform)\n",
    "        val_dataset = FireSegmentationDataset(val_img, val_mask, transform=None)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "        \n",
    "        # Callbacks específicos do fold\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='validation_epoch_average',\n",
    "            dirpath=f'checkpoints/{arch}_fold_{fold}',  # Adicione o nome da arquitetura\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            mode='min'\n",
    "        )\n",
    "        lr_scheduler_callback = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor='validation_epoch_average',  # Monitorando a perda de validação\n",
    "            patience=3,                          # Número de épocas sem melhoria para parar\n",
    "            #verbose=True,                        # Exibe mensagens de log quando ocorrer o early stopping\n",
    "            mode='min'                           # Estamos tentando minimizar a perda\n",
    "        )\n",
    "        logger = TensorBoardLogger(\"tb_logs\", name=f\"{model.arch}_fold_{fold}\")\n",
    "        \n",
    "        # Configura o Trainer\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=100,\n",
    "            callbacks=[early_stop_callback, checkpoint_callback, lr_scheduler_callback],\n",
    "            logger=logger,\n",
    "            accelerator=\"auto\",\n",
    "            log_every_n_steps=1\n",
    "        )\n",
    "        \n",
    "        # Treina o modelo no fold atual\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "        # Check if early stopping was triggered\n",
    "        if early_stop_callback.stopped_epoch != 0:\n",
    "            print(f\"Early stopping triggered at epoch {early_stop_callback.stopped_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes/Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FireSegmentationDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "# Carrega os melhores modelos de cada fold\n",
    "models = []\n",
    "for fold in range(num_folds):\n",
    "    model_path = f'checkpoints/fold_{fold}/best_model.ckpt'\n",
    "    model = FireModel.load_from_checkpoint(model_path)\n",
    "    models.append(model)\n",
    "\n",
    "# Avalia cada modelo no conjunto de teste\n",
    "results = []\n",
    "for model in models:\n",
    "    result = trainer.test(model, test_loader)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
